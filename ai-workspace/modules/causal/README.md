# ZenGlow Causal Inference Module

## Overview

The ZenGlow Causal Inference Module provides rigorous causal analysis capabilities to determine the true effectiveness of wellness interventions on child outcomes. This module moves beyond simple correlation analysis to establish causal relationships using state-of-the-art causal inference methods.

## Purpose

**Problem**: Traditional analytics can only show correlation (e.g., "stress levels are lower on days with mindfulness activities"), but cannot determine causation.

**Solution**: This module uses causal inference to answer questions like:
- Does mindfulness *actually cause* stress reduction?
- By how much do breathing exercises *causally* improve sleep quality?
- Which interventions have the strongest *causal* effect for each child?

## Key Features

### ðŸ”¬ Rigorous Causal Analysis
- Uses DoWhy (Microsoft Research) for robust causal inference
- Implements backdoor criterion and propensity score methods
- Provides confidence intervals and statistical significance testing

### ðŸ›¡ï¸ Defensive Programming
- Guarded imports prevent crashes when heavy libraries aren't installed
- Graceful fallback to simple statistical analysis
- Comprehensive error handling and logging

### ðŸ“Š Mock Data Generation
- Realistic mock wellness data for testing and development
- Consistent per-child data using seeded random generation
- Simulates intervention effects and confounding variables

### ðŸš€ Easy Integration
- Simple API: `analyze_causal_effect(child_id)`
- CLI interface for testing and demonstrations
- Structured for easy database integration

## Usage

### Basic Usage

```python
from modules.causal import analyze_causal_effect

# Analyze causal effect for a specific child
result = analyze_causal_effect('child_123')

print(f"Causal Effect: {result['causal_effect']}")
print(f"Interpretation: {result['interpretation']}")
```

### CLI Usage

```bash
# Run full demo with sample children
python3 run_causal_analysis.py

# Analyze specific child
python3 run_causal_analysis.py child_123

# Or use the module directly
python3 -m modules.causal.causal_inference
```

### Output Format

```json
{
  "child_id": "child_123",
  "causal_effect": -15.2,
  "confidence_interval": [-22.1, -8.3],
  "interpretation": "Interventions reduce stress by 15.2 points",
  "sample_size": 30,
  "method_used": "dowhy",
  "significant": true
}
```

## Architecture

### Data Flow

```
Mock Data Generation â†’ Causal Model â†’ Effect Estimation â†’ Results
      â†“                     â†“              â†“              â†“
[Historical Data]    [DoWhy Model]   [Backdoor Method]  [JSON Output]
```

### Planned Database Integration

The module is designed to seamlessly integrate with ZenGlow's database:

```sql
SELECT
    w.time,
    w.stress_level,
    w.sleep_duration,
    s.event_type AS intervention,
    s.event_time
FROM wellness_metrics w
LEFT JOIN school_events s ON
    w.child_id = s.child_id AND
    date_trunc('day', w.time) = date_trunc('day', s.event_time)
WHERE w.child_id = '{child_id}'
ORDER BY w.time
```

### Analysis Methods

1. **DoWhy Analysis** (when available):
   - Causal model identification
   - Backdoor criterion adjustment
   - Propensity score stratification
   - Robust standard errors

2. **Fallback Analysis** (when DoWhy unavailable):
   - Simple difference-in-means comparison
   - Basic statistical significance testing
   - Conservative confidence intervals

## Dependencies

### Core Dependencies (Required)
- `pandas`: Data manipulation and analysis
- `numpy`: Numerical computing
- `logging`: Error and warning handling

### Advanced Dependencies (Optional)
- `dowhy>=0.11.0`: Microsoft's causal inference library
- `causalml>=0.15.0`: Advanced causal ML methods

### Installation

```bash
# Install core dependencies
pip install pandas numpy

# Install advanced causal inference libraries (when ready)
pip install dowhy causalml
```

**Note**: Advanced dependencies are intentionally commented out in `requirements.txt` to prevent installation of heavyweight libraries during development. Uncomment when ready for production deployment.

## Development

### Mock Data Structure

The module generates realistic mock data with:
- **Baseline patterns**: Natural variation in stress and sleep
- **Intervention effects**: 10-30% stress reduction when interventions occur
- **Confounding variables**: Sleep duration affects both stress and intervention likelihood
- **Temporal patterns**: Time-based trends and seasonal effects

### Error Handling

- **Import Protection**: Graceful degradation when libraries unavailable
- **Data Validation**: Comprehensive checks for invalid inputs
- **Logging**: Detailed logging for debugging and monitoring
- **Fallback Methods**: Alternative analysis when primary methods fail

### Testing

```bash
# Test basic functionality
python3 -c "from modules.causal import analyze_causal_effect; print(analyze_causal_effect('test'))"

# Test CLI interface
python3 run_causal_analysis.py test_child

# Run full demo
python3 -m modules.causal.causal_inference
```

## Integration Roadmap

### Phase 1: Mock Analysis âœ…
- [x] Basic module structure
- [x] Mock data generation
- [x] Fallback statistical analysis
- [x] CLI interface

### Phase 2: Database Integration (Planned)
- [ ] Connect to Supabase/PostgreSQL database
- [ ] Implement SQL query for real data
- [ ] Add data validation and cleaning
- [ ] Handle missing data scenarios

### Phase 3: Advanced Causal Methods (Planned)
- [ ] Install and configure DoWhy
- [ ] Implement multiple causal identification strategies
- [ ] Add CausalML for personalized treatment effects
- [ ] Include sensitivity analysis

### Phase 4: API Integration (Planned)
- [ ] Flask/FastAPI endpoints
- [ ] Real-time causal analysis
- [ ] Caching for performance
- [ ] A/B testing support

## Expected Results

With mock data, typical results show:
- **Stress Reduction**: 5-20 point decrease (on 0-100 scale)
- **Effect Size**: Moderate to large effects (Cohen's d > 0.5)
- **Confidence**: 95% confidence intervals around estimates
- **Significance**: Approximately 60% of analyses show significant effects

## Best Practices

### For Developers
1. **Always use guarded imports** for optional dependencies
2. **Validate inputs** before processing
3. **Log extensively** for debugging
4. **Provide fallbacks** for missing dependencies
5. **Structure for testability** with mock data

### For Data Scientists
1. **Check sample sizes** before interpreting results
2. **Examine confidence intervals** for uncertainty
3. **Consider confounding variables** in interpretation
4. **Validate assumptions** of causal models
5. **Report limitations** clearly

## Support

For questions or issues:
1. Check the logging output for detailed error messages
2. Verify all required dependencies are installed
3. Test with mock data before using real data
4. Review the causal model assumptions

## References

- [DoWhy Documentation](https://microsoft.github.io/dowhy/)
- [CausalML Documentation](https://causalml.readthedocs.io/)
- [Causal Inference: The Mixtape](https://mixtape.scunning.com/)
- [Causal Inference for Statistics](https://www.cambridge.org/core/books/causal-inference-for-statistics-social-and-biomedical-sciences/71126BE90C58F1A431FE9B2DD07938AB)